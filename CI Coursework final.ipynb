{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52c272e",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca2e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5693e944",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtarfile\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "import torch\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "from numpy import argmax\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import io\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52f62c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba903b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697daf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=unpickle(\"data_batch_1\")\n",
    "data2=unpickle(\"data_batch_2\")\n",
    "data3=unpickle(\"data_batch_3\")\n",
    "data4=unpickle(\"data_batch_4\")\n",
    "data5=unpickle(\"data_batch_5\")\n",
    "test=unpickle(\"test_batch\")\n",
    "\n",
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data1=data1[b'data']\n",
    "x_data2=data2[b'data']\n",
    "x_data3=data3[b'data']\n",
    "x_data4=data4[b'data']\n",
    "x_data5=data5[b'data']\n",
    "\n",
    "y_data1=data1[b'labels']\n",
    "y_data2=data2[b'labels']\n",
    "y_data3=data3[b'labels']\n",
    "y_data4=data4[b'labels']\n",
    "y_data5=data5[b'labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554ae9f",
   "metadata": {},
   "source": [
    "### Concatenating all the datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.concatenate((x_data1,x_data2,x_data3,x_data4,x_data5),axis=0)\n",
    "y_train=np.concatenate((y_data1,y_data2,y_data3,y_data4,y_data5),axis=0)\n",
    "\n",
    "print('length of training set: ' + str(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c56447",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=x_train.reshape(len(x_train),3,32,32).transpose(0,2,3,1)\n",
    "y_train=to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc557b6",
   "metadata": {},
   "source": [
    "#### Loading the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=unpickle('test_batch')\n",
    "X_test=test[b'data'].reshape(len(test[b'data']),3,32,32).transpose(0,2,3,1)\n",
    "y_test=to_categorical(test[b'labels'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf9f9c",
   "metadata": {},
   "source": [
    "### dataset characteristics of data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd0e5a",
   "metadata": {},
   "source": [
    "### shape of a single image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2571b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c288a",
   "metadata": {},
   "source": [
    "### plotting the train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050a57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,9):\n",
    "    plt.subplot(330+1+i)\n",
    "    itrain = X_train[i]\n",
    "    plt.imshow(itrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a6e568",
   "metadata": {},
   "source": [
    "### plotting test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15259956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,9):\n",
    "    plt.subplot(330+1+i)\n",
    "    itest = X_test[i]\n",
    "    plt.imshow(itest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70977ad",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80c2f9",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c377ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c03ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ed3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= nor\n",
    "X_test /= nor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99485169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ac352",
   "metadata": {},
   "source": [
    "### class labels shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCls=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc0179",
   "metadata": {},
   "source": [
    "# SGD ## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e426de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (3,3)\n",
    "st = (1,1)\n",
    "ish = (32,32,3)\n",
    "act = 'relu'\n",
    "pad = 'same'\n",
    "ps = (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ab057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperactive import Hyperactive\n",
    "from hyperactive.optimizers import ParticleSwarmOptimizer\n",
    "from keras.models import Sequential\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    Activation,\n",
    ")\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db570cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd =Sequential() \n",
    "sgd.add(Conv2D(50, (3, 3), strides=st, padding=pad, input_shape=ish))\n",
    "sgd.add(Activation(\"relu\"))\n",
    "    \n",
    "sgd.add(Conv2D(125, (3, 3), strides=st, padding=pad, activation=act))\n",
    "sgd.add(MaxPool2D(pool_size=ps))\n",
    "sgd.add(Dropout(0.25))\n",
    "    \n",
    "sgd.add(Conv2D(125, (3, 3), strides=st, padding=pad, activation=act))\n",
    "sgd.add(MaxPool2D(pool_size=ps))\n",
    "sgd.add(Dropout(0.25))\n",
    "    \n",
    "sgd.add(Flatten(input_shape=ish))\n",
    "sgd.add(Dense(500, act))\n",
    "sgd.add(Dropout(0.5))\n",
    "sgd.add(Dense(250, act))\n",
    "sgd.add(Dropout(0.5))\n",
    "sgd.add(Dense(10, activation='softmax'))\n",
    "opt = SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "sgd.fit(X_train, y_train, epochs=50, batch_size=128)\n",
    "sgd.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab07b8",
   "metadata": {},
   "source": [
    "# PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2075f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperactive import Hyperactive\n",
    "from hyperactive.optimizers import ParticleSwarmOptimizer\n",
    "from keras.models import Sequential\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    Activation,\n",
    ")\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa05fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(opt):\n",
    "    nn = Sequential()\n",
    "    nn.add(Conv2D(opt[\"filter.0\"],(3, 3),padding=\"same\",input_shape=X_train.shape[1:],))\n",
    "    nn.add(Activation(\"relu\"))\n",
    "    nn.add(Conv2D(opt[\"filter.0\"], (3, 3)))\n",
    "    nn.add(Activation(\"relu\"))\n",
    "    nn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    nn.add(Dropout(0.25))\n",
    "\n",
    "    nn.add(Conv2D(opt[\"filter.0\"], (3, 3), padding=\"same\"))\n",
    "    nn.add(Activation(\"relu\"))\n",
    "    nn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    nn.add(Dropout(0.25))\n",
    "\n",
    "    nn.add(Flatten())\n",
    "    nn.add(Dense(opt[\"layer.0\"]))\n",
    "    nn.add(Activation(\"relu\"))\n",
    "    nn.add(Dropout(0.5))\n",
    "    nn.add(Dense(opt[\"layer.0\"]))\n",
    "    nn.add(Activation(\"relu\"))\n",
    "    nn.add(Dropout(0.5))\n",
    "    nn.add(Dense(10))\n",
    "    nn.add(Activation(\"softmax\"))\n",
    "\n",
    "    nn.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    nn.fit(X_train, y_train, epochs=50, batch_size=128)\n",
    "\n",
    "    _, score = nn.evaluate(x=X_test, y=y_test)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"filter.0\": [50,125,125],\n",
    "    \"layer.0\": [500,250],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = ParticleSwarmOptimizer(\n",
    "    inertia=0.4,\n",
    "    cognitive_weight=0.7,\n",
    "    social_weight=0.7,\n",
    "    temp_weight=0.3,\n",
    "    rand_rest_p=0.05,\n",
    ")\n",
    "\n",
    "hyper = Hyperactive()\n",
    "hyper.add_search(model, search_space, optimizer=optimizer, n_iter=1)\n",
    "hyper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c35af9",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b6429",
   "metadata": {},
   "source": [
    "###  sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57246945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d4094",
   "metadata": {},
   "source": [
    "### convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1dcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (3,3)\n",
    "st = (1,1)\n",
    "ish = (32,32,3)\n",
    "act = 'relu'\n",
    "pad = 'same'\n",
    "ps = (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add(Conv2D(50, kernel_size=ks, strides=st, padding=pad, activation=act, input_shape=ish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bef312",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add(Conv2D(125, kernel_size=ks, strides=st, padding=pad, activation=act))\n",
    "v.add(MaxPool2D(pool_size=ps))\n",
    "v.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add(Conv2D(125, kernel_size=ks, strides=st, padding=pad, activation=act))\n",
    "v.add(MaxPool2D(pool_size=ps))\n",
    "v.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047ffa0",
   "metadata": {},
   "source": [
    "### flatten output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add(Flatten(input_shape=ish))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905f6a5",
   "metadata": {},
   "source": [
    "### hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277372d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add(Dense(500, act))\n",
    "v.add(Dropout(0.5))\n",
    "v.add(Dense(250, act))\n",
    "v.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6fb27",
   "metadata": {},
   "source": [
    "### output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c4093",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0532f",
   "metadata": {},
   "source": [
    "### compiling the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80416cfe",
   "metadata": {},
   "source": [
    "### training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92112a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.fit(X_train, y_train, batch_size=128, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aefb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metrics = pd.DataFrame(v.history.history)\n",
    "metrics[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e8506",
   "metadata": {},
   "source": [
    "### Evaluating both the train  and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb6573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e8d06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3764bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
